### ASCII码
计算机发明后, 为了在计算机中表示字符, 人们制定了一种编码 ASCII码, 将字符和二进制数一一对照 <br>
最开始的时候,使用的是一个byte（字节）的7位bit表示也就是最大表示0x00 - 0x7F, 共128个字符 <br>
这个用来表示英文字符已经够用了, 但是后来发现还有许多其他的符号，比如说制表符 <br>
发现不够用了之后, 就扩展了ASCII码, 使用8位bit来表示0x00 - 0xFF, 共256个字符， 后面的128个字符就叫拓展ASCII码. <br>
每个ASCII码占用一个字节

  
### GB2312
但是对于中文来说, 256个字符是远远不够的<br>
不止中国, 各个国家都仿照这一方案来制定自己国家的文字编码规范, 其中中文的文字编码规范 <br>
叫做 ‘GB2312’, 使用的是两个ASCII码表示一个中文字符, 所以一个中文对应两个字节 （ASCII码）<br>
高字节和低字节, 高字节是必须大于127的数, 低字节最开始也是必须大于127的数, 后来是只要高字节大于127就行, 低字节随意.<br>

由于每个国家和地区都使用自己的文字编码规范，互相冲突， 对于信息交互来说是很麻烦的.<br>

### UNICODE
要真正解决这个问题，不能从扩展ASCII 的角度入手，UNICODE作为一个全新的编码系统应运而生，它可以将中文、法文、德文……等等所有的文字统一起来考虑，为每一个文字都分配一个单独的编码。在都使用unicode的情况下，  即便我们在本地查看别的国家的网站看不懂内容，但起码不会乱码

UNICODE码占用两个字节， 可以表示256*256 = 65536个字符，其中汉字就占用了4万多个字符..一个UNICODE码对应一个字符， 两个字节。

这里就存在一个问题， 对于英文字母来说， 一个字节就足够表示了， 但是unicode强制要求用两个字节， 这样所有的英文字符前一个字节是0， 对于存储空间来说是很浪费的， <br>
假设一个文件都是英文，使用ASCII码，5K就足够存储了， 那么使用unicode码的话， 大小变成了10K， 浪费了5K的空间。

那么UTF-8， UTF-16这些有代表什么呢？<br>

### UTF-8 UTF-16
为解决unicode如何在网络上传输的问题，于是面向传输的众多 UTF（UCS Transfer Format）标准出现了，<br>
顾名思义，UTF-8就是每次8个位传输数据，而UTF-16就是每次16个位。<br>
UTF-8就是在互联网上使用最广的一种unicode的实现方式，这是为传输而设计的编码，并使编码无国界，这样就可以显示全世界上所有文化的字符了。
UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度，当字符在ASCII码的范围时，就用一个字节表示，保留了ASCII字符一个字节的编码做为它的一部分
注意的是unicode一个中文字符占2个字节，而UTF-8一个中文字符占3个字节。<br>
从unicode到utf-8并不是直接的对应，而是要过一些算法和规则来转换。<br>

例子如下：<br>
计算机只懂二进制，因此，严格按照unicode的方式(UCS-2)，应该这样存储：<br>
I： 00000000 01001001<br>
t： 00000000 01110100<br>
知： 01110111 11100101<br>

这个字符串总共占用了6个字节，但是对比中英文的二进制码，可以发现，英文前9位都是0！浪费啊，浪费硬盘，浪费流量。
怎么办？<br>
UTF <br>
UTF-8是这样做的：<br>
1. 单字节的字符，字节的第一位设为0，对于英语文本，UTF-8码只占用一个字节，和ASCII码完全相同；
2. n个字节的字符(n>1)，第一个字节的前n位设为1，第n+1位设为0，后面字节的前两位都设为10，这n个字节的其余空位填充该字符unicode码，高位用0补足。
这样就形成了如下的UTF-8标记位：<br>
0xxxxxxx<br>
110xxxxx 10xxxxxx<br>
1110xxxx 10xxxxxx 10xxxxxx<br>
11110xxx 10xxxxxx 10xxxxxx 10xxxxxx<br>
111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx<br>
1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx<br>
... ...<br>
于是，就变成了：<br>
I： 01001001<br>
t：01110100<br>
知： 11100111 10011111 10100101<br>

和上边的方案对比一下，英文短了，每个中文字符却多用了一个字节。但是整个字符串只用了5个字节，比上边的6个短了一点点。

通过上面的这个例子， 我们可以把unicode当成一个字符集，UTF-8当成一种编码方式。

在Unicode中：汉字“字”对应的数字是23383， 16进制表示为0x5b57
在Unicode中，我们有很多方式将数字23383表示成程序中的数据，包括：UTF-8、UTF-16、UTF-32。
UTF是“UCS Transformation Format”的缩写，可以翻译成Unicode字符集转换格式，即怎样将Unicode定义的数字转换成程序数据。
使用UTF-8，汉字“字”被转化为：0xE5, 0xAD, 0x97<br>

||unicode码 |16进制  | 2进制 | UTF-8转化结果（3个字节）|
|--|:--:|--:|
|字|23383|0x5b57| 0101 1011 0101 0111   | 0xE5, 0xAD, 0x97|


         unicode码     16进制                   2进制                                   UTF-8转化结果（3个字节）
字        23383         0x5b57        0101 1011 0101 0111                           0xE5, 0xAD, 0x97

所以这一切都是为了节省硬盘存储空间和流量

### 最后
总的来说
ASCII 码是最初一个字符集， 主要为了英文字符在计算机中表示
通过对 ASCII 编码的中文扩充改造，产生了 GB2312 编码，可以表示6000多个常用汉字。
汉字实在是太多了，包括繁体和各种字符，于是产生了 GBK 编码，它包括了 GB2312 中的编码，同时扩充了很多。
中国是个多民族国家，各个民族几乎都有自己独立的语言系统，为了表示那些字符，继续把 GBK 编码扩充为 GB18030 编码。
每个国家都像中国一样，把自己的语言编码，于是出现了各种各样的编码，如果你不安装相应的编码，就无法解释相应编码想表达的内容。
终于，有个叫 ISO 的组织看不下去了。他们一起创造了一种编码 UNICODE ，这种编码非常大，大到可以容纳世界上任何一个文字和标志。所以只要电脑上有 UNICODE 这种编码系统，无论是全球哪种文字，只需要保存文件的时候，保存成 UNICODE 编码就可以被其他电脑正常解释。
Unicode也可以简单当成一个字符集， UTF-8 和UTF-16是对unicode码的一种「编码规则

参考地址： https://www.zhihu.com/question/23374078
